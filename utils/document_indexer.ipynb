{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Content Processor for Azure AI Search\n",
    "\n",
    "This notebook provides tools for processing PDF documents and preparing them for Azure AI Search. It includes functionality for:\n",
    "- PDF text extraction using PyMuPDF\n",
    "- Content chunking and processing\n",
    "- Embedding generation using Azure OpenAI\n",
    "- Azure AI Search index creation and population\n",
    "\n",
    "## Setup and Dependencies\n",
    "First, let's import all required libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "import dotenv\n",
    "import tqdm\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Azure and OpenAI related imports\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes.models import (\n",
    "    ScoringProfile,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    TextWeights,\n",
    ")\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_community.document_loaders import AzureAIDocumentIntelligenceLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI, AzureOpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores.azuresearch import AzureSearch\n",
    "\n",
    "# Load environment variables\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Set up the paths and configuration parameters for document processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory configuration\n",
    "BASE_DIR = \"../doc/Temario\"\n",
    "PDF_DIR = os.path.join(BASE_DIR, \"temas_por_secciones\")\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, \"../data/output\")\n",
    "METADATA_FILE = os.path.join(PDF_DIR, \"document_label.yaml\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Load metadata from YAML file\n",
    "with open(METADATA_FILE, 'r') as file:\n",
    "    metadata = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Processing Functions\n",
    "Core functions for extracting and processing content from PDF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdfs(pdf_dir: str, metadata: dict) -> list:\n",
    "    \"\"\"\n",
    "    Extract text content from PDF files in the specified directory.\n",
    "    \n",
    "    Args:\n",
    "        pdf_dir (str): Directory containing PDF files\n",
    "        metadata (dict): Dictionary containing metadata for each PDF\n",
    "    \n",
    "    Returns:\n",
    "        list: List of dictionaries containing extracted text and metadata for each page\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    for filename in os.listdir(pdf_dir):\n",
    "        if not filename.endswith(\".pdf\"):\n",
    "            continue\n",
    "            \n",
    "        path = os.path.join(pdf_dir, filename)\n",
    "        doc = fitz.open(path)\n",
    "        \n",
    "        # Get metadata for the current file\n",
    "        metadata_key = filename.split('.')[0]\n",
    "        metadata_info = metadata.get(metadata_key, {})\n",
    "        skills = metadata_info.get('skills', [])\n",
    "        if not isinstance(skills, list):\n",
    "            skills = [skills]\n",
    "            \n",
    "        subject = metadata_info.get('subject', 'Unknown Subject')\n",
    "        difficulty = metadata_info.get('difficulty', 'Unknown Difficulty')\n",
    "        description = metadata_info.get('description', 'No Description')\n",
    "\n",
    "        # Process each page\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc[page_num]\n",
    "            text = page.get_text()\n",
    "            \n",
    "            # Extract chapter information from first page\n",
    "            chapter_number = None\n",
    "            chapter_title = None\n",
    "            if page_num == 0:\n",
    "                match_page = re.search(r\"\\b(\\d{3})\\b\", text)\n",
    "                match_title = re.search(r\"C\\nH\\nA\\nP\\nT\\nE\\nR\\n(.*?)\\nCONTENTS\", text, re.DOTALL)\n",
    "                \n",
    "                chapter_number = int(match_page.group(1)) if match_page else None\n",
    "                chapter_title = match_title.group(1).strip() if match_title else None\n",
    "\n",
    "            # Create document entry\n",
    "            documents.append({\n",
    "                'filename': filename,\n",
    "                'page_number': chapter_number + page_num if chapter_number else page_num + 1,\n",
    "                'text': text,\n",
    "                'skills': skills,\n",
    "                'subject': subject,\n",
    "                'difficulty': difficulty,\n",
    "                'description': description,\n",
    "                'chapter_title': chapter_title\n",
    "            })\n",
    "            \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Processing and Chunking\n",
    "Process the extracted documents and split them into manageable chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_documents(pages: list) -> tuple:\n",
    "    \"\"\"\n",
    "    Convert raw pages into LangChain documents and split them into chunks.\n",
    "    \n",
    "    Args:\n",
    "        pages (list): List of page dictionaries from PDF processing\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (LangChain documents, chunks)\n",
    "    \"\"\"\n",
    "    # Convert pages to LangChain documents\n",
    "    docs = []\n",
    "    for page in pages:\n",
    "        docs.append(Document(\n",
    "            page_content=page[\"text\"], \n",
    "            metadata={\n",
    "                \"page_number\": str(page[\"page_number\"]), \n",
    "                \"filename\": str(page[\"filename\"]),\n",
    "                \"skills\": page[\"skills\"],\n",
    "                \"subject\": page[\"subject\"],\n",
    "                \"difficulty\": page[\"difficulty\"],\n",
    "                \"description\": page[\"description\"],\n",
    "                \"chapter_title\": page[\"chapter_title\"]\n",
    "            }\n",
    "        ))\n",
    "    \n",
    "    # Split documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1300,\n",
    "        chunk_overlap=100,\n",
    "        add_start_index=True\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(docs)\n",
    "    \n",
    "    return docs, chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure AI Search Setup\n",
    "Configure and create the Azure AI Search index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_search_index_schema(embedding_dimension: int) -> list:\n",
    "    \"\"\"\n",
    "    Create the schema for Azure AI Search index.\n",
    "    \n",
    "    Args:\n",
    "        embedding_dimension (int): Dimension of the embedding vectors\n",
    "    \n",
    "    Returns:\n",
    "        list: List of field definitions for the search index\n",
    "    \"\"\"\n",
    "    return [\n",
    "        SimpleField(\n",
    "            name=\"id\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            key=True,\n",
    "            filterable=True,\n",
    "        ),\n",
    "        SearchableField(\n",
    "            name=\"content\", \n",
    "            type=SearchFieldDataType.String,\n",
    "            searchable=True\n",
    "        ),\n",
    "        SearchableField(name=\"metadata\", \n",
    "                        type=SearchFieldDataType.String, \n",
    "                        searchable=True),\n",
    "        SearchField(\n",
    "            name=\"content_vector\",\n",
    "            type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "            searchable=True,\n",
    "            vector_search_dimensions=embedding_dimension,\n",
    "            vector_search_profile_name=\"myHnswProfile\"\n",
    "        ),\n",
    "        SimpleField(\n",
    "            name=\"page_number\",\n",
    "            type=SearchFieldDataType.Int32,\n",
    "            filterable=True,\n",
    "            facetable=True,\n",
    "            sortable=True\n",
    "        ),\n",
    "        SearchableField(\n",
    "            name=\"skills\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            searchable=True,\n",
    "            collection=True\n",
    "        ),\n",
    "        SearchableField(\n",
    "            name=\"subject\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            searchable=True\n",
    "        ),\n",
    "        SearchableField(\n",
    "            name=\"difficulty\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            searchable=True\n",
    "        ),\n",
    "        SearchableField(\n",
    "            name=\"description\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            searchable=True\n",
    "        ),\n",
    "        SearchableField(\n",
    "            name=\"filename\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            searchable=True\n",
    "        ),\n",
    "        SimpleField(\n",
    "            name=\"start_index\",\n",
    "            type=SearchFieldDataType.Int32,\n",
    "            searchable=True\n",
    "        ),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Processing Pipeline\n",
    "Execute the complete document processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from PDFs...\n",
      "Processing documents and creating chunks...\n",
      "Generating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [01:15<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving processed pages...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:00<00:00, 686.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating and populating Azure AI Search index...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You need to specify at least the following fields {'metadata': 'Edm.String'} or provide alternative field names in the env variables.\n\nmetadata current type: 'MISSING'. It has to be 'Edm.String' or you can point to a different 'Edm.String' field name by using the env variable 'AZURESEARCH_FIELDS_METADATA'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceNotFoundError\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/tutoria/lib/python3.9/site-packages/langchain_community/vectorstores/azuresearch.py:169\u001b[0m, in \u001b[0;36m_get_search_client\u001b[0;34m(endpoint, index_name, key, azure_ad_access_token, semantic_configuration_name, fields, vector_search, semantic_configurations, scoring_profiles, default_scoring_profile, default_fields, user_agent, cors_options, async_, additional_search_client_options, azure_credential, azure_async_credential)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     \u001b[43mindex_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ResourceNotFoundError:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m# Fields configuration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tutoria/lib/python3.9/site-packages/azure/core/tracing/decorator.py:119\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tracing_enabled \u001b[38;5;129;01mand\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tutoria/lib/python3.9/site-packages/azure/search/documents/indexes/_search_index_client.py:155\u001b[0m, in \u001b[0;36mSearchIndexClient.get_index\u001b[0;34m(self, name, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_client_headers(kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m--> 155\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(SearchIndex, SearchIndex\u001b[38;5;241m.\u001b[39m_from_generated(result))\n",
      "File \u001b[0;32m~/miniconda3/envs/tutoria/lib/python3.9/site-packages/azure/core/tracing/decorator.py:119\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tracing_enabled \u001b[38;5;129;01mand\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tutoria/lib/python3.9/site-packages/azure/search/documents/indexes/_generated/operations/_indexes_operations.py:847\u001b[0m, in \u001b[0;36mIndexesOperations.get\u001b[0;34m(self, index_name, request_options, **kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m200\u001b[39m]:\n\u001b[0;32m--> 847\u001b[0m     \u001b[43mmap_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    848\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize\u001b[38;5;241m.\u001b[39mfailsafe_deserialize(_models\u001b[38;5;241m.\u001b[39mErrorResponse, pipeline_response)\n",
      "File \u001b[0;32m~/miniconda3/envs/tutoria/lib/python3.9/site-packages/azure/core/exceptions.py:163\u001b[0m, in \u001b[0;36mmap_error\u001b[0;34m(status_code, response, error_map)\u001b[0m\n\u001b[1;32m    162\u001b[0m error \u001b[38;5;241m=\u001b[39m error_type(response\u001b[38;5;241m=\u001b[39mresponse)\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[0;31mResourceNotFoundError\u001b[0m: () No index with the name 'temario-index-v4' was found in the service 'tutoria-rag-engine-aais'.\nCode: \nMessage: No index with the name 'temario-index-v4' was found in the service 'tutoria-rag-engine-aais'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Execute the main pipeline\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 34\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating and populating Azure AI Search index...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m index_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemario-index-v4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 34\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m \u001b[43mAzureSearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mazure_search_endpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAZURE_SEARCH_ENDPOINT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mazure_search_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAZURE_SEARCH_KEY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_search_client_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mretry_total\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_search_index_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Add chunks to vector store in batches\u001b[39;00m\n\u001b[1;32m     44\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/tutoria/lib/python3.9/site-packages/langchain_community/vectorstores/azuresearch.py:364\u001b[0m, in \u001b[0;36mAzureSearch.__init__\u001b[0;34m(self, azure_search_endpoint, azure_search_key, index_name, embedding_function, search_type, semantic_configuration_name, fields, vector_search, semantic_configurations, scoring_profiles, default_scoring_profile, cors_options, vector_search_dimensions, additional_search_client_options, azure_ad_access_token, azure_credential, azure_async_credential, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m     user_agent \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_agent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# Create sync client\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43m_get_search_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mazure_search_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mazure_search_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mazure_ad_access_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43msemantic_configuration_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msemantic_configuration_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvector_search\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvector_search\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43msemantic_configurations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msemantic_configurations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring_profiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoring_profiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_scoring_profile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_scoring_profile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcors_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcors_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_search_client_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_search_client_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mazure_credential\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mazure_credential\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# Create async client\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client \u001b[38;5;241m=\u001b[39m _get_search_client(\n\u001b[1;32m    384\u001b[0m     azure_search_endpoint,\n\u001b[1;32m    385\u001b[0m     index_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m     azure_async_credential\u001b[38;5;241m=\u001b[39mazure_async_credential,\n\u001b[1;32m    401\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/tutoria/lib/python3.9/site-packages/langchain_community/vectorstores/azuresearch.py:193\u001b[0m, in \u001b[0;36m_get_search_client\u001b[0;34m(endpoint, index_name, key, azure_ad_access_token, semantic_configuration_name, fields, vector_search, semantic_configurations, scoring_profiles, default_scoring_profile, default_fields, user_agent, cors_options, async_, additional_search_client_options, azure_credential, azure_async_credential)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    186\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m current type: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfields_types\u001b[38;5;241m.\u001b[39mget(x,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMISSING\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    187\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt has to be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmandatory_fields\u001b[38;5;241m.\u001b[39mget(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or you can point \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto a different \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmandatory_fields\u001b[38;5;241m.\u001b[39mget(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m field name by \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing the env variable \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAZURESEARCH_FIELDS_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m             )\n\u001b[1;32m    192\u001b[0m         error \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([fmt_err(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m missing_fields])\n\u001b[0;32m--> 193\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    194\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to specify at least the following fields \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    195\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_fields\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or provide alternative field names in the env \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    196\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariables.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    197\u001b[0m         )\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     fields \u001b[38;5;241m=\u001b[39m default_fields\n",
      "\u001b[0;31mValueError\u001b[0m: You need to specify at least the following fields {'metadata': 'Edm.String'} or provide alternative field names in the env variables.\n\nmetadata current type: 'MISSING'. It has to be 'Edm.String' or you can point to a different 'Edm.String' field name by using the env variable 'AZURESEARCH_FIELDS_METADATA'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main processing pipeline for PDF documents.\"\"\"\n",
    "    # Initialize Azure OpenAI embeddings\n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        azure_deployment=\"text-embedding-ada-002\",\n",
    "        openai_api_version=\"2024-02-01\"\n",
    "    )\n",
    "    \n",
    "    # Extract text from PDFs\n",
    "    print(\"Extracting text from PDFs...\")\n",
    "    pages = extract_text_from_pdfs(PDF_DIR, metadata)\n",
    "    \n",
    "    # Process documents and create chunks\n",
    "    print(\"Processing documents and creating chunks...\")\n",
    "    docs, chunks = process_documents(pages)\n",
    "    \n",
    "    # Generate embeddings for each page\n",
    "    #print(\"Generating embeddings...\")\n",
    "    #for page in tqdm.tqdm(pages):\n",
    "    #    page[\"embedding\"] = embeddings.embed_query(page[\"text\"])\n",
    "    \n",
    "    \n",
    "    # Create and populate Azure AI Search index\n",
    "    print(\"Creating and populating Azure AI Search index...\")\n",
    "    index_name = \"temario-index-v4\"\n",
    "    vector_store = AzureSearch(\n",
    "        embedding_function=embeddings.embed_query,\n",
    "        azure_search_endpoint=os.getenv(\"AZURE_SEARCH_ENDPOINT\"),\n",
    "        azure_search_key=os.getenv(\"AZURE_SEARCH_KEY\"),\n",
    "        index_name=index_name,\n",
    "        additional_search_client_options={\"retry_total\": 3},\n",
    "        fields=create_search_index_schema(len(embeddings.embed_query(\"test\")))\n",
    "    )\n",
    "    \n",
    "    # Add chunks to vector store in batches\n",
    "    batch_size = 500\n",
    "    for i in tqdm.tqdm(range(0, len(chunks), batch_size)):\n",
    "        content_batch = [chunk.page_content for chunk in chunks[i:i + batch_size]]\n",
    "        metadata_batch = [chunk.metadata for chunk in chunks[i:i + batch_size]]\n",
    "        vector_store.add_texts(texts=content_batch, metadatas=metadata_batch)\n",
    "    \n",
    "    print(\"Processing complete!\")\n",
    "\n",
    "# Execute the main pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Search Index\n",
    "Test the created search index with a sample query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_search(query: str, vector_store: AzureSearch):\n",
    "    \"\"\"\n",
    "    Test the search index with a sample query.\n",
    "    \n",
    "    Args:\n",
    "        query (str): Search query\n",
    "        vector_store (AzureSearch): Initialized Azure Search instance\n",
    "    \"\"\"\n",
    "    results = vector_store.similarity_search(query)\n",
    "    \n",
    "    print(f\"Search results for query: '{query}'\\n\")\n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"Result {i}:\")\n",
    "        print(f\"Content: {result.page_content[:200]}...\")\n",
    "        print(f\"Page Number: {result.metadata['page_number']}\")\n",
    "        print(f\"Chapter Title: {result.metadata.get('chapter_title', 'N/A')}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "# Example search\n",
    "test_search(\"What is the main topic of the document?\", vector_store)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutoria",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
